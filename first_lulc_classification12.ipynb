{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.regularizers import l2\n",
    "from keras import optimizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import shuffle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unnamed: 0', 'Unnamed: 0.1', 'lat', 'lon', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B9', 'B11', 'B12', 'class']\n",
      "class : 0 is emptyland   class : 1 is urban   class : 2 is vegetation   class : 3 is waterbody  \n"
     ]
    }
   ],
   "source": [
    "os.chdir('C:/Users/trainee201995/Desktop/anaconda') \n",
    "filename = 'final_data.csv'\n",
    "dataset = pd.read_csv(filename)\n",
    "dataset = shuffle(dataset)\n",
    "print(list(dataset))\n",
    "print(\"class : 0 is emptyland   \" + \"class : 1 is urban   \" + \"class : 2 is vegetation   \" + \"class : 3 is waterbody  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "Class_ID = dataset[['class']]\n",
    "X = dataset[['B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B9', 'B11', 'B12']]\n",
    "Y = np.ravel(Class_ID)\n",
    "X = X\n",
    "\n",
    "#print(X,Y)\n",
    "#print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1026, 11)\n",
      "(1027, 11)\n",
      "(1026,)\n",
      "(1027,)\n",
      "768\n",
      "258\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.50,)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)\n",
    "print(np.sum(Y_train==0))\n",
    "print(np.sum(Y_train==1))\n",
    "print(np.sum(Y_train==2))\n",
    "print(np.sum(Y_train==3))\n",
    "#print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10112721 0.17385827 0.12829227 0.44461634 0.60312862 0.57531056\n",
      " 0.65565736 0.61293583 0.51702533 0.58432871 0.45596591]\n",
      "[0.19220056 0.29357413 0.32163743 0.65962364 0.61491375 0.59285714\n",
      " 0.64878269 0.60531448 0.75164474 0.76013679 0.75167121]\n"
     ]
    }
   ],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "X_train = min_max_scaler.fit_transform(X_train)\n",
    "X_test = min_max_scaler.fit_transform(X_test)\n",
    "print(X_train[0])\n",
    "print(X_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_num_units = 11\n",
    "hidden1_num_units = 4\n",
    "hidden2_num_units = 16\n",
    "hidden3_num_units = 4\n",
    "\n",
    "output_num_units = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=11, kernel_regularizer=<keras.reg..., activation=\"relu\", units=4)`\n",
      "  \n",
      "E:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=4, kernel_regularizer=<keras.reg..., activation=\"relu\", units=16)`\n",
      "  after removing the cwd from sys.path.\n",
      "E:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=16, kernel_regularizer=<keras.reg..., activation=\"relu\", units=4)`\n",
      "  \n",
      "E:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=4, activation=\"softmax\", units=2)`\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(output_dim=hidden1_num_units, input_dim=input_num_units, kernel_regularizer=l2(0.0001), activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(output_dim=hidden2_num_units, input_dim=hidden1_num_units, kernel_regularizer=l2(0.0001), activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(output_dim=hidden3_num_units, input_dim=hidden2_num_units,  kernel_regularizer=l2(0.0001), activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    \n",
    "    Dense(output_dim=output_num_units, input_dim=hidden3_num_units, activation='softmax'),\n",
    " ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_187 (Dense)            (None, 4)                 48        \n",
      "_________________________________________________________________\n",
      "dropout_160 (Dropout)        (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_188 (Dense)            (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dropout_161 (Dropout)        (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_189 (Dense)            (None, 4)                 68        \n",
      "_________________________________________________________________\n",
      "dropout_162 (Dropout)        (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_190 (Dense)            (None, 2)                 10        \n",
      "=================================================================\n",
      "Total params: 206\n",
      "Trainable params: 206\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = keras.optimizers.Adam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.01, amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1026/1026 [==============================] - 3s 3ms/step - loss: 0.7220 - acc: 0.5078\n",
      "Epoch 2/200\n",
      "1026/1026 [==============================] - 0s 25us/step - loss: 0.6014 - acc: 0.6881\n",
      "Epoch 3/200\n",
      "1026/1026 [==============================] - 0s 21us/step - loss: 0.5768 - acc: 0.7173\n",
      "Epoch 4/200\n",
      "1026/1026 [==============================] - 0s 26us/step - loss: 0.5658 - acc: 0.7251\n",
      "Epoch 5/200\n",
      "1026/1026 [==============================] - 0s 21us/step - loss: 0.5567 - acc: 0.7398\n",
      "Epoch 6/200\n",
      "1026/1026 [==============================] - 0s 26us/step - loss: 0.5662 - acc: 0.7398\n",
      "Epoch 7/200\n",
      "1026/1026 [==============================] - 0s 23us/step - loss: 0.5613 - acc: 0.7281\n",
      "Epoch 8/200\n",
      "1026/1026 [==============================] - 0s 24us/step - loss: 0.5573 - acc: 0.7427\n",
      "Epoch 9/200\n",
      "1026/1026 [==============================] - 0s 21us/step - loss: 0.5469 - acc: 0.7417\n",
      "Epoch 10/200\n",
      "1026/1026 [==============================] - 0s 26us/step - loss: 0.5496 - acc: 0.7407\n",
      "Epoch 11/200\n",
      "1026/1026 [==============================] - 0s 20us/step - loss: 0.5412 - acc: 0.7417\n",
      "Epoch 12/200\n",
      "1026/1026 [==============================] - 0s 26us/step - loss: 0.5425 - acc: 0.7437\n",
      "Epoch 13/200\n",
      "1026/1026 [==============================] - 0s 27us/step - loss: 0.5373 - acc: 0.7427\n",
      "Epoch 14/200\n",
      "1026/1026 [==============================] - 0s 25us/step - loss: 0.5302 - acc: 0.7456\n",
      "Epoch 15/200\n",
      "1026/1026 [==============================] - 0s 24us/step - loss: 0.5425 - acc: 0.7446\n",
      "Epoch 16/200\n",
      "1026/1026 [==============================] - 0s 23us/step - loss: 0.5322 - acc: 0.7427\n",
      "Epoch 17/200\n",
      "1026/1026 [==============================] - 0s 23us/step - loss: 0.5321 - acc: 0.7485\n",
      "Epoch 18/200\n",
      "1026/1026 [==============================] - 0s 25us/step - loss: 0.5258 - acc: 0.7466\n",
      "Epoch 19/200\n",
      "1026/1026 [==============================] - 0s 23us/step - loss: 0.5188 - acc: 0.7485\n",
      "Epoch 20/200\n",
      "1026/1026 [==============================] - 0s 23us/step - loss: 0.5256 - acc: 0.7476\n",
      "Epoch 21/200\n",
      "1026/1026 [==============================] - 0s 23us/step - loss: 0.5146 - acc: 0.7485\n",
      "Epoch 22/200\n",
      "1026/1026 [==============================] - 0s 25us/step - loss: 0.5143 - acc: 0.7476\n",
      "Epoch 23/200\n",
      "1026/1026 [==============================] - 0s 22us/step - loss: 0.5149 - acc: 0.7476\n",
      "Epoch 24/200\n",
      "1026/1026 [==============================] - 0s 24us/step - loss: 0.5045 - acc: 0.7485\n",
      "Epoch 25/200\n",
      "1026/1026 [==============================] - 0s 27us/step - loss: 0.5144 - acc: 0.7466\n",
      "Epoch 26/200\n",
      "1026/1026 [==============================] - 0s 24us/step - loss: 0.5062 - acc: 0.7485\n",
      "Epoch 27/200\n",
      "1026/1026 [==============================] - 0s 25us/step - loss: 0.5059 - acc: 0.7485\n",
      "Epoch 28/200\n",
      "1026/1026 [==============================] - 0s 25us/step - loss: 0.5013 - acc: 0.7485\n",
      "Epoch 29/200\n",
      "1026/1026 [==============================] - 0s 24us/step - loss: 0.5126 - acc: 0.7485\n",
      "Epoch 30/200\n",
      "1026/1026 [==============================] - 0s 26us/step - loss: 0.4977 - acc: 0.7485\n",
      "Epoch 31/200\n",
      "1026/1026 [==============================] - 0s 22us/step - loss: 0.4982 - acc: 0.7476\n",
      "Epoch 32/200\n",
      "1026/1026 [==============================] - 0s 22us/step - loss: 0.4888 - acc: 0.7485\n",
      "Epoch 33/200\n",
      "1026/1026 [==============================] - 0s 22us/step - loss: 0.4930 - acc: 0.7485\n",
      "Epoch 34/200\n",
      "1026/1026 [==============================] - 0s 24us/step - loss: 0.4924 - acc: 0.7485\n",
      "Epoch 35/200\n",
      "1026/1026 [==============================] - 0s 24us/step - loss: 0.4843 - acc: 0.7485\n",
      "Epoch 36/200\n",
      "1026/1026 [==============================] - 0s 22us/step - loss: 0.4920 - acc: 0.7476\n",
      "Epoch 37/200\n",
      "1026/1026 [==============================] - 0s 24us/step - loss: 0.4900 - acc: 0.7485\n",
      "Epoch 38/200\n",
      "1026/1026 [==============================] - 0s 20us/step - loss: 0.4823 - acc: 0.7485\n",
      "Epoch 39/200\n",
      "1026/1026 [==============================] - 0s 26us/step - loss: 0.4739 - acc: 0.7476\n",
      "Epoch 40/200\n",
      "1026/1026 [==============================] - 0s 21us/step - loss: 0.4681 - acc: 0.7485\n",
      "Epoch 41/200\n",
      "1026/1026 [==============================] - 0s 27us/step - loss: 0.4654 - acc: 0.7485\n",
      "Epoch 42/200\n",
      "1026/1026 [==============================] - 0s 25us/step - loss: 0.4567 - acc: 0.7476\n",
      "Epoch 43/200\n",
      "1026/1026 [==============================] - 0s 22us/step - loss: 0.4619 - acc: 0.7485\n",
      "Epoch 44/200\n",
      "1026/1026 [==============================] - 0s 22us/step - loss: 0.4651 - acc: 0.7485\n",
      "Epoch 45/200\n",
      "1026/1026 [==============================] - 0s 23us/step - loss: 0.4472 - acc: 0.7485\n",
      "Epoch 46/200\n",
      "1026/1026 [==============================] - 0s 22us/step - loss: 0.4449 - acc: 0.7485\n",
      "Epoch 47/200\n",
      "1026/1026 [==============================] - 0s 42us/step - loss: 0.4452 - acc: 0.7485\n",
      "Epoch 48/200\n",
      "1026/1026 [==============================] - 0s 24us/step - loss: 0.4452 - acc: 0.7485\n",
      "Epoch 49/200\n",
      "1026/1026 [==============================] - 0s 26us/step - loss: 0.4421 - acc: 0.7485\n",
      "Epoch 50/200\n",
      "1026/1026 [==============================] - 0s 26us/step - loss: 0.4338 - acc: 0.7485\n",
      "Epoch 51/200\n",
      "1026/1026 [==============================] - 0s 24us/step - loss: 0.4410 - acc: 0.7476\n",
      "Epoch 52/200\n",
      "1026/1026 [==============================] - 0s 26us/step - loss: 0.4315 - acc: 0.7485\n",
      "Epoch 53/200\n",
      "1026/1026 [==============================] - 0s 44us/step - loss: 0.4228 - acc: 0.7485\n",
      "Epoch 54/200\n",
      "1026/1026 [==============================] - 0s 21us/step - loss: 0.4213 - acc: 0.7485\n",
      "Epoch 55/200\n",
      "1026/1026 [==============================] - 0s 22us/step - loss: 0.4096 - acc: 0.7485\n",
      "Epoch 56/200\n",
      "1026/1026 [==============================] - 0s 22us/step - loss: 0.4164 - acc: 0.7485\n",
      "Epoch 57/200\n",
      "1026/1026 [==============================] - 0s 23us/step - loss: 0.4124 - acc: 0.7485\n",
      "Epoch 58/200\n",
      "1026/1026 [==============================] - 0s 22us/step - loss: 0.4088 - acc: 0.7485\n",
      "Epoch 59/200\n",
      "1026/1026 [==============================] - 0s 26us/step - loss: 0.3982 - acc: 0.7485\n",
      "Epoch 60/200\n",
      "1026/1026 [==============================] - 0s 24us/step - loss: 0.3982 - acc: 0.7476\n",
      "Epoch 61/200\n",
      "1026/1026 [==============================] - 0s 23us/step - loss: 0.3941 - acc: 0.7485\n",
      "Epoch 62/200\n",
      "1026/1026 [==============================] - 0s 27us/step - loss: 0.3882 - acc: 0.7485\n",
      "Epoch 63/200\n",
      "1026/1026 [==============================] - 0s 25us/step - loss: 0.3776 - acc: 0.7485\n",
      "Epoch 64/200\n",
      "1026/1026 [==============================] - 0s 28us/step - loss: 0.3767 - acc: 0.7485\n",
      "Epoch 65/200\n",
      "1026/1026 [==============================] - 0s 22us/step - loss: 0.3794 - acc: 0.7485\n",
      "Epoch 66/200\n",
      "1026/1026 [==============================] - 0s 20us/step - loss: 0.3738 - acc: 0.7485\n",
      "Epoch 67/200\n",
      "1026/1026 [==============================] - 0s 22us/step - loss: 0.3709 - acc: 0.7456\n",
      "Epoch 68/200\n",
      "1026/1026 [==============================] - 0s 21us/step - loss: 0.3676 - acc: 0.7476\n",
      "Epoch 69/200\n",
      "1026/1026 [==============================] - 0s 21us/step - loss: 0.3588 - acc: 0.7485\n",
      "Epoch 70/200\n",
      "1026/1026 [==============================] - 0s 21us/step - loss: 0.3544 - acc: 0.7485\n",
      "Epoch 71/200\n",
      "1026/1026 [==============================] - 0s 20us/step - loss: 0.3505 - acc: 0.7749\n",
      "Epoch 72/200\n",
      "1026/1026 [==============================] - 0s 21us/step - loss: 0.3503 - acc: 0.8324\n",
      "Epoch 73/200\n",
      "1026/1026 [==============================] - 0s 22us/step - loss: 0.3578 - acc: 0.8294\n",
      "Epoch 74/200\n",
      "1026/1026 [==============================] - 0s 21us/step - loss: 0.3467 - acc: 0.8596\n",
      "Epoch 75/200\n",
      "1026/1026 [==============================] - 0s 22us/step - loss: 0.3452 - acc: 0.8470\n",
      "Epoch 76/200\n",
      "1026/1026 [==============================] - 0s 24us/step - loss: 0.3314 - acc: 0.8577\n",
      "Epoch 77/200\n",
      "1026/1026 [==============================] - 0s 22us/step - loss: 0.3453 - acc: 0.8733\n",
      "Epoch 78/200\n",
      "1026/1026 [==============================] - 0s 48us/step - loss: 0.3327 - acc: 0.8538\n",
      "Epoch 79/200\n",
      "1026/1026 [==============================] - 0s 23us/step - loss: 0.3442 - acc: 0.8879\n",
      "Epoch 80/200\n",
      "1026/1026 [==============================] - 0s 25us/step - loss: 0.3334 - acc: 0.8762\n",
      "Epoch 81/200\n",
      "1026/1026 [==============================] - 0s 27us/step - loss: 0.3332 - acc: 0.8713\n",
      "Epoch 82/200\n",
      "1026/1026 [==============================] - 0s 28us/step - loss: 0.3201 - acc: 0.8743\n",
      "Epoch 83/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1026/1026 [==============================] - 0s 24us/step - loss: 0.3252 - acc: 0.8782\n",
      "Epoch 84/200\n",
      "1026/1026 [==============================] - 0s 26us/step - loss: 0.3321 - acc: 0.9084\n",
      "Epoch 85/200\n",
      "1026/1026 [==============================] - 0s 20us/step - loss: 0.3269 - acc: 0.8986\n",
      "Epoch 86/200\n",
      "1026/1026 [==============================] - 0s 21us/step - loss: 0.3226 - acc: 0.8850\n",
      "Epoch 87/200\n",
      "1026/1026 [==============================] - 0s 20us/step - loss: 0.3210 - acc: 0.8840\n",
      "Epoch 88/200\n",
      "1026/1026 [==============================] - 0s 21us/step - loss: 0.3055 - acc: 0.8957\n",
      "Epoch 89/200\n",
      "1026/1026 [==============================] - 0s 21us/step - loss: 0.3037 - acc: 0.8947\n",
      "Epoch 90/200\n",
      "1026/1026 [==============================] - 0s 22us/step - loss: 0.3028 - acc: 0.9006\n",
      "Epoch 91/200\n",
      "1026/1026 [==============================] - 0s 21us/step - loss: 0.3038 - acc: 0.9074\n",
      "Epoch 92/200\n",
      "1026/1026 [==============================] - 0s 27us/step - loss: 0.3045 - acc: 0.8967\n",
      "Epoch 93/200\n",
      "1026/1026 [==============================] - 0s 24us/step - loss: 0.3061 - acc: 0.8986\n",
      "Epoch 94/200\n",
      "1026/1026 [==============================] - 0s 27us/step - loss: 0.2890 - acc: 0.9074\n",
      "Epoch 95/200\n",
      "1026/1026 [==============================] - 0s 25us/step - loss: 0.2947 - acc: 0.9094\n",
      "Epoch 96/200\n",
      "1026/1026 [==============================] - 0s 26us/step - loss: 0.2910 - acc: 0.9084\n",
      "Epoch 97/200\n",
      "1026/1026 [==============================] - 0s 26us/step - loss: 0.3030 - acc: 0.9064\n",
      "Epoch 98/200\n",
      "1026/1026 [==============================] - 0s 28us/step - loss: 0.2984 - acc: 0.9162\n",
      "Epoch 99/200\n",
      "1026/1026 [==============================] - 0s 24us/step - loss: 0.2809 - acc: 0.9201\n",
      "Epoch 100/200\n",
      "1026/1026 [==============================] - 0s 26us/step - loss: 0.2852 - acc: 0.9094\n",
      "Epoch 101/200\n",
      "1026/1026 [==============================] - 0s 21us/step - loss: 0.2836 - acc: 0.9181\n",
      "Epoch 102/200\n",
      "1026/1026 [==============================] - 0s 22us/step - loss: 0.2792 - acc: 0.9230\n",
      "Epoch 103/200\n",
      "1026/1026 [==============================] - 0s 21us/step - loss: 0.2789 - acc: 0.9172\n",
      "Epoch 104/200\n",
      "1026/1026 [==============================] - 0s 21us/step - loss: 0.2710 - acc: 0.9220\n",
      "Epoch 105/200\n",
      "1026/1026 [==============================] - 0s 22us/step - loss: 0.2847 - acc: 0.9152\n",
      "Epoch 106/200\n",
      "1026/1026 [==============================] - 0s 21us/step - loss: 0.2723 - acc: 0.9172\n",
      "Epoch 107/200\n",
      "1026/1026 [==============================] - 0s 20us/step - loss: 0.2722 - acc: 0.9181\n",
      "Epoch 108/200\n",
      "1026/1026 [==============================] - 0s 23us/step - loss: 0.2740 - acc: 0.9152\n",
      "Epoch 109/200\n",
      "1026/1026 [==============================] - 0s 21us/step - loss: 0.2619 - acc: 0.9376\n",
      "Epoch 110/200\n",
      "1026/1026 [==============================] - 0s 22us/step - loss: 0.2735 - acc: 0.9162\n",
      "Epoch 111/200\n",
      "1026/1026 [==============================] - 0s 21us/step - loss: 0.2546 - acc: 0.9347\n",
      "Epoch 112/200\n",
      "1026/1026 [==============================] - 0s 21us/step - loss: 0.2739 - acc: 0.9279\n",
      "Epoch 113/200\n",
      "1026/1026 [==============================] - 0s 22us/step - loss: 0.2698 - acc: 0.9288\n",
      "Epoch 114/200\n",
      "1026/1026 [==============================] - 0s 20us/step - loss: 0.2721 - acc: 0.9211\n",
      "Epoch 115/200\n",
      "1026/1026 [==============================] - 0s 25us/step - loss: 0.2625 - acc: 0.9259\n",
      "Epoch 116/200\n",
      "1026/1026 [==============================] - 0s 22us/step - loss: 0.2589 - acc: 0.9308\n",
      "Epoch 117/200\n",
      "1026/1026 [==============================] - 0s 22us/step - loss: 0.2546 - acc: 0.9337\n",
      "Epoch 118/200\n",
      "1026/1026 [==============================] - 0s 22us/step - loss: 0.2474 - acc: 0.9298\n",
      "Epoch 119/200\n",
      "1026/1026 [==============================] - 0s 21us/step - loss: 0.2554 - acc: 0.9279\n",
      "Epoch 120/200\n",
      "1026/1026 [==============================] - 0s 20us/step - loss: 0.2583 - acc: 0.9347\n",
      "Epoch 121/200\n",
      "1026/1026 [==============================] - 0s 25us/step - loss: 0.2556 - acc: 0.9279\n",
      "Epoch 122/200\n",
      "1026/1026 [==============================] - 0s 22us/step - loss: 0.2539 - acc: 0.9269\n",
      "Epoch 123/200\n",
      "1026/1026 [==============================] - 0s 24us/step - loss: 0.2626 - acc: 0.9337\n",
      "Epoch 124/200\n",
      "1026/1026 [==============================] - 0s 22us/step - loss: 0.2595 - acc: 0.9279\n",
      "Epoch 125/200\n",
      "1026/1026 [==============================] - 0s 24us/step - loss: 0.2416 - acc: 0.9464\n",
      "Epoch 126/200\n",
      "1026/1026 [==============================] - 0s 22us/step - loss: 0.2494 - acc: 0.9327\n",
      "Epoch 127/200\n",
      "1026/1026 [==============================] - 0s 24us/step - loss: 0.2414 - acc: 0.9376\n",
      "Epoch 128/200\n",
      "1026/1026 [==============================] - 0s 24us/step - loss: 0.2355 - acc: 0.9357\n",
      "Epoch 129/200\n",
      "1026/1026 [==============================] - 0s 27us/step - loss: 0.2337 - acc: 0.9337\n",
      "Epoch 130/200\n",
      "1026/1026 [==============================] - 0s 24us/step - loss: 0.2356 - acc: 0.9444\n",
      "Epoch 131/200\n",
      "1026/1026 [==============================] - 0s 22us/step - loss: 0.2321 - acc: 0.9318\n",
      "Epoch 132/200\n",
      "1026/1026 [==============================] - 0s 25us/step - loss: 0.2406 - acc: 0.9298\n",
      "Epoch 133/200\n",
      "1026/1026 [==============================] - 0s 21us/step - loss: 0.2359 - acc: 0.9357\n",
      "Epoch 134/200\n",
      "1026/1026 [==============================] - 0s 24us/step - loss: 0.2336 - acc: 0.9386\n",
      "Epoch 135/200\n",
      "1026/1026 [==============================] - 0s 21us/step - loss: 0.2340 - acc: 0.9347\n",
      "Epoch 136/200\n",
      "1026/1026 [==============================] - 0s 20us/step - loss: 0.2318 - acc: 0.9464\n",
      "Epoch 137/200\n",
      "1026/1026 [==============================] - 0s 20us/step - loss: 0.2379 - acc: 0.9327\n",
      "Epoch 138/200\n",
      "1026/1026 [==============================] - 0s 21us/step - loss: 0.2319 - acc: 0.9357\n",
      "Epoch 139/200\n",
      "1026/1026 [==============================] - 0s 22us/step - loss: 0.2262 - acc: 0.9405\n",
      "Epoch 140/200\n",
      "1026/1026 [==============================] - 0s 22us/step - loss: 0.2171 - acc: 0.9503\n",
      "Epoch 141/200\n",
      "1026/1026 [==============================] - 0s 21us/step - loss: 0.2329 - acc: 0.9337\n",
      "Epoch 142/200\n",
      "1026/1026 [==============================] - 0s 24us/step - loss: 0.2344 - acc: 0.9386\n",
      "Epoch 143/200\n",
      "1026/1026 [==============================] - 0s 45us/step - loss: 0.2251 - acc: 0.9376\n",
      "Epoch 144/200\n",
      "1026/1026 [==============================] - 0s 23us/step - loss: 0.2270 - acc: 0.9308\n",
      "Epoch 145/200\n",
      "1026/1026 [==============================] - 0s 25us/step - loss: 0.2250 - acc: 0.9444\n",
      "Epoch 146/200\n",
      "1026/1026 [==============================] - 0s 22us/step - loss: 0.2232 - acc: 0.9415\n",
      "Epoch 147/200\n",
      "1026/1026 [==============================] - 0s 25us/step - loss: 0.2261 - acc: 0.9366\n",
      "Epoch 148/200\n",
      "1026/1026 [==============================] - 0s 23us/step - loss: 0.2171 - acc: 0.9435\n",
      "Epoch 149/200\n",
      "1026/1026 [==============================] - 0s 23us/step - loss: 0.2319 - acc: 0.9347\n",
      "Epoch 150/200\n",
      "1026/1026 [==============================] - 0s 21us/step - loss: 0.2268 - acc: 0.9376\n",
      "Epoch 151/200\n",
      "1026/1026 [==============================] - 0s 21us/step - loss: 0.2263 - acc: 0.9347\n",
      "Epoch 152/200\n",
      "1026/1026 [==============================] - 0s 24us/step - loss: 0.2113 - acc: 0.9376\n",
      "Epoch 153/200\n",
      "1026/1026 [==============================] - 0s 22us/step - loss: 0.2147 - acc: 0.9405\n",
      "Epoch 154/200\n",
      "1026/1026 [==============================] - 0s 24us/step - loss: 0.2198 - acc: 0.9405\n",
      "Epoch 155/200\n",
      "1026/1026 [==============================] - 0s 22us/step - loss: 0.2201 - acc: 0.9474\n",
      "Epoch 156/200\n",
      "1026/1026 [==============================] - 0s 23us/step - loss: 0.2125 - acc: 0.9425\n",
      "Epoch 157/200\n",
      "1026/1026 [==============================] - 0s 24us/step - loss: 0.2082 - acc: 0.9493\n",
      "Epoch 158/200\n",
      "1026/1026 [==============================] - 0s 22us/step - loss: 0.2210 - acc: 0.9454\n",
      "Epoch 159/200\n",
      "1026/1026 [==============================] - 0s 24us/step - loss: 0.2185 - acc: 0.9415\n",
      "Epoch 160/200\n",
      "1026/1026 [==============================] - 0s 20us/step - loss: 0.2103 - acc: 0.9386\n",
      "Epoch 161/200\n",
      "1026/1026 [==============================] - 0s 25us/step - loss: 0.2100 - acc: 0.9357\n",
      "Epoch 162/200\n",
      "1026/1026 [==============================] - 0s 22us/step - loss: 0.2024 - acc: 0.9454\n",
      "Epoch 163/200\n",
      "1026/1026 [==============================] - 0s 23us/step - loss: 0.2163 - acc: 0.9376\n",
      "Epoch 164/200\n",
      "1026/1026 [==============================] - 0s 23us/step - loss: 0.2066 - acc: 0.9444\n",
      "Epoch 165/200\n",
      "1026/1026 [==============================] - 0s 24us/step - loss: 0.2140 - acc: 0.9376\n",
      "Epoch 166/200\n",
      "1026/1026 [==============================] - 0s 22us/step - loss: 0.2119 - acc: 0.9444\n",
      "Epoch 167/200\n",
      "1026/1026 [==============================] - 0s 23us/step - loss: 0.2097 - acc: 0.9396\n",
      "Epoch 168/200\n",
      "1026/1026 [==============================] - 0s 23us/step - loss: 0.1943 - acc: 0.9513\n",
      "Epoch 169/200\n",
      "1026/1026 [==============================] - 0s 24us/step - loss: 0.2000 - acc: 0.9464\n",
      "Epoch 170/200\n",
      "1026/1026 [==============================] - 0s 40us/step - loss: 0.2178 - acc: 0.9386\n",
      "Epoch 171/200\n",
      "1026/1026 [==============================] - 0s 25us/step - loss: 0.1965 - acc: 0.9464\n",
      "Epoch 172/200\n",
      "1026/1026 [==============================] - 0s 22us/step - loss: 0.2009 - acc: 0.9483\n",
      "Epoch 173/200\n",
      "1026/1026 [==============================] - 0s 23us/step - loss: 0.2070 - acc: 0.9444\n",
      "Epoch 174/200\n",
      "1026/1026 [==============================] - 0s 23us/step - loss: 0.1974 - acc: 0.9435\n",
      "Epoch 175/200\n",
      "1026/1026 [==============================] - 0s 20us/step - loss: 0.2008 - acc: 0.9405\n",
      "Epoch 176/200\n",
      "1026/1026 [==============================] - 0s 21us/step - loss: 0.2167 - acc: 0.9318\n",
      "Epoch 177/200\n",
      "1026/1026 [==============================] - 0s 21us/step - loss: 0.2045 - acc: 0.9454\n",
      "Epoch 178/200\n",
      "1026/1026 [==============================] - 0s 21us/step - loss: 0.1951 - acc: 0.9503\n",
      "Epoch 179/200\n",
      "1026/1026 [==============================] - 0s 20us/step - loss: 0.2010 - acc: 0.9357\n",
      "Epoch 180/200\n",
      "1026/1026 [==============================] - 0s 21us/step - loss: 0.2039 - acc: 0.9444\n",
      "Epoch 181/200\n",
      "1026/1026 [==============================] - 0s 22us/step - loss: 0.2080 - acc: 0.9357\n",
      "Epoch 182/200\n",
      "1026/1026 [==============================] - 0s 20us/step - loss: 0.1940 - acc: 0.9474\n",
      "Epoch 183/200\n",
      "1026/1026 [==============================] - 0s 21us/step - loss: 0.2141 - acc: 0.9308\n",
      "Epoch 184/200\n",
      "1026/1026 [==============================] - 0s 21us/step - loss: 0.1976 - acc: 0.9454\n",
      "Epoch 185/200\n",
      "1026/1026 [==============================] - 0s 22us/step - loss: 0.2172 - acc: 0.9405\n",
      "Epoch 186/200\n",
      "1026/1026 [==============================] - 0s 24us/step - loss: 0.1981 - acc: 0.9425\n",
      "Epoch 187/200\n",
      "1026/1026 [==============================] - 0s 29us/step - loss: 0.2012 - acc: 0.9454\n",
      "Epoch 188/200\n",
      "1026/1026 [==============================] - 0s 26us/step - loss: 0.2040 - acc: 0.9357\n",
      "Epoch 189/200\n",
      "1026/1026 [==============================] - 0s 23us/step - loss: 0.1766 - acc: 0.9474\n",
      "Epoch 190/200\n",
      "1026/1026 [==============================] - 0s 57us/step - loss: 0.1990 - acc: 0.9444\n",
      "Epoch 191/200\n",
      "1026/1026 [==============================] - 0s 25us/step - loss: 0.1934 - acc: 0.9444\n",
      "Epoch 192/200\n",
      "1026/1026 [==============================] - 0s 21us/step - loss: 0.1986 - acc: 0.9405\n",
      "Epoch 193/200\n",
      "1026/1026 [==============================] - 0s 21us/step - loss: 0.2064 - acc: 0.9386\n",
      "Epoch 194/200\n",
      "1026/1026 [==============================] - 0s 22us/step - loss: 0.1907 - acc: 0.9376\n",
      "Epoch 195/200\n",
      "1026/1026 [==============================] - 0s 21us/step - loss: 0.2007 - acc: 0.9415\n",
      "Epoch 196/200\n",
      "1026/1026 [==============================] - 0s 20us/step - loss: 0.1826 - acc: 0.9386\n",
      "Epoch 197/200\n",
      "1026/1026 [==============================] - 0s 22us/step - loss: 0.1936 - acc: 0.9483\n",
      "Epoch 198/200\n",
      "1026/1026 [==============================] - 0s 21us/step - loss: 0.2022 - acc: 0.9366\n",
      "Epoch 199/200\n",
      "1026/1026 [==============================] - 0s 20us/step - loss: 0.1997 - acc: 0.9474\n",
      "Epoch 200/200\n",
      "1026/1026 [==============================] - 0s 23us/step - loss: 0.1925 - acc: 0.9454\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X_train, \n",
    "          Y_train,\n",
    "          epochs=200, \n",
    "          batch_size=64, \n",
    "          validation_split = 0.0,\n",
    "          verbose=1,\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'acc'])\n"
     ]
    }
   ],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'val_acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-464-c8c85eddaae7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'epoch'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'val_acc'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'val_loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-465-ae52a7ab008a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# summarize history for loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'val_loss'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1027/1027 [==============================] - 1s 923us/step\n",
      "(1027, 11)\n",
      "(1027, 2)\n",
      "[0.24361399788238985, 0.9250243513354308]\n",
      "Baseline Error: 7.50%\n"
     ]
    }
   ],
   "source": [
    "Y_pred = model.predict(X_test)\n",
    "score = model.evaluate(X_test, Y_test,batch_size=100, verbose=1)\n",
    "print(X_test.shape)\n",
    "print(Y_pred.shape)\n",
    "print(score)\n",
    "print(\"Baseline Error: %.2f%%\" % (100-score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1027,)\n",
      "(1027, 11)\n",
      "[1 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "test_class = model.predict_classes(X_test)\n",
    "print(test_class.shape)\n",
    "print(X_test.shape)\n",
    "print(test_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confussion matrix:\n",
      "[[775  10]\n",
      " [ 67 175]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confussion matrix:\\n%s\" %\n",
    "      metrics.confusion_matrix(Y_test, test_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.92      0.99      0.95       785\n",
      "        True       0.95      0.72      0.82       242\n",
      "\n",
      "   micro avg       0.93      0.93      0.93      1027\n",
      "   macro avg       0.93      0.86      0.89      1027\n",
      "weighted avg       0.93      0.93      0.92      1027\n",
      "\n",
      "Classification accuracy: 0.925024\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report:\\n%s\" %\n",
    "      metrics.classification_report(Y_test, test_class))\n",
    "print(\"Classification accuracy: %f\" %\n",
    "      metrics.accuracy_score(Y_test, test_class))\n",
    "#print(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(77.51050546955403, 8.983152841195215e-05, 0.0, 30.381202571979042, 0.0, -8.983152841195215e-05)\n"
     ]
    }
   ],
   "source": [
    "import osr\n",
    "import gdal \n",
    "import math\n",
    "arr = {}\n",
    "ten_meter  = {2:\"B2\",3:\"B3\",4:\"B4\",8:\"B8\"}\n",
    "twenty_meter = {5:'B5',6:'B6',7:'B7',9:'B8A',10:'B9',11:'B11',12:'B12'}\n",
    "ds = gdal.Open(\"final_data_2.tif\")\n",
    "temp = ds.GetGeoTransform()\n",
    "band = ds.GetRasterBand(2)\n",
    "arr1 = band.ReadAsArray()\n",
    "arr[2] = arr1\n",
    "inp_data = np.zeros((11,arr[2].shape[0],arr[2].shape[1]),dtype = 'float64')\n",
    "print(temp)\n",
    "\n",
    "for no,col in ten_meter.items() :\n",
    "    band = ds.GetRasterBand(no)\n",
    "    arr1 = band.ReadAsArray()\n",
    "    arr[no] = arr1 \n",
    "    inp_data[no-2] =arr1\n",
    "for no,col in twenty_meter.items() :\n",
    "    band = ds.GetRasterBand(no)\n",
    "    arr1 = band.ReadAsArray()\n",
    "    arr[no] = arr1 \n",
    "    inp_data[no-2] = arr1\n",
    "inp_data = np.zeros((11,arr[2].shape[0],arr[2].shape[1]),dtype = 'float64')\n",
    "temp_arr = np.zeros((1,11),dtype='float64')\n",
    "classified_arr = np.zeros((arr[2].shape[0],arr[2].shape[1]),dtype = 'float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0th row over !!!![[   0 4811    0    0]]\n",
      "1th row over !!!![[   0 9622    0    0]]\n",
      "2th row over !!!![[    0 14433     0     0]]\n",
      "3th row over !!!![[    0 19244     0     0]]\n",
      "4th row over !!!![[    0 24055     0     0]]\n",
      "5th row over !!!![[    0 28866     0     0]]\n",
      "6th row over !!!![[    0 33677     0     0]]\n",
      "7th row over !!!![[    0 38488     0     0]]\n",
      "8th row over !!!![[    0 43299     0     0]]\n",
      "9th row over !!!![[    0 48110     0     0]]\n",
      "10th row over !!!![[    0 52921     0     0]]\n",
      "11th row over !!!![[    0 57732     0     0]]\n",
      "12th row over !!!![[    0 62543     0     0]]\n",
      "13th row over !!!![[    0 67354     0     0]]\n",
      "14th row over !!!![[    0 72165     0     0]]\n",
      "15th row over !!!![[    0 76976     0     0]]\n",
      "16th row over !!!![[    0 81787     0     0]]\n",
      "17th row over !!!![[    0 86598     0     0]]\n",
      "18th row over !!!![[    0 91409     0     0]]\n",
      "19th row over !!!![[    0 96220     0     0]]\n",
      "20th row over !!!![[     0 101031      0      0]]\n",
      "21th row over !!!![[     0 105842      0      0]]\n",
      "22th row over !!!![[     0 110653      0      0]]\n",
      "23th row over !!!![[     0 115464      0      0]]\n",
      "24th row over !!!![[     0 120275      0      0]]\n",
      "25th row over !!!![[     0 125086      0      0]]\n",
      "26th row over !!!![[     0 129897      0      0]]\n",
      "27th row over !!!![[     0 134708      0      0]]\n",
      "28th row over !!!![[     0 139519      0      0]]\n",
      "29th row over !!!![[     0 144330      0      0]]\n",
      "30th row over !!!![[     0 149141      0      0]]\n",
      "31th row over !!!![[     0 153952      0      0]]\n",
      "32th row over !!!![[     0 158763      0      0]]\n",
      "33th row over !!!![[     0 163574      0      0]]\n",
      "34th row over !!!![[     0 168385      0      0]]\n",
      "35th row over !!!![[     0 173196      0      0]]\n",
      "36th row over !!!![[     0 178007      0      0]]\n",
      "37th row over !!!![[     0 182818      0      0]]\n",
      "38th row over !!!![[     0 187629      0      0]]\n",
      "39th row over !!!![[     0 192440      0      0]]\n",
      "40th row over !!!![[     0 197251      0      0]]\n",
      "41th row over !!!![[     0 202062      0      0]]\n",
      "42th row over !!!![[     0 206873      0      0]]\n",
      "43th row over !!!![[     0 211684      0      0]]\n",
      "44th row over !!!![[     0 216495      0      0]]\n",
      "45th row over !!!![[     0 221306      0      0]]\n",
      "46th row over !!!![[     0 226117      0      0]]\n",
      "47th row over !!!![[     0 230928      0      0]]\n",
      "48th row over !!!![[     0 235739      0      0]]\n",
      "49th row over !!!![[     0 240550      0      0]]\n",
      "50th row over !!!![[     0 245361      0      0]]\n",
      "51th row over !!!![[     0 250172      0      0]]\n",
      "52th row over !!!![[     0 254983      0      0]]\n",
      "53th row over !!!![[     0 259794      0      0]]\n",
      "54th row over !!!![[     0 264605      0      0]]\n",
      "55th row over !!!![[     0 269416      0      0]]\n",
      "56th row over !!!![[     0 274227      0      0]]\n",
      "57th row over !!!![[     0 279038      0      0]]\n",
      "58th row over !!!![[     0 283849      0      0]]\n",
      "59th row over !!!![[     0 288660      0      0]]\n",
      "60th row over !!!![[     0 293471      0      0]]\n",
      "61th row over !!!![[     0 298282      0      0]]\n",
      "62th row over !!!![[     0 303093      0      0]]\n",
      "63th row over !!!![[     0 307904      0      0]]\n",
      "64th row over !!!![[     0 312715      0      0]]\n",
      "65th row over !!!![[     0 317526      0      0]]\n",
      "66th row over !!!![[     0 322337      0      0]]\n",
      "67th row over !!!![[     0 327148      0      0]]\n",
      "68th row over !!!![[     0 331959      0      0]]\n",
      "69th row over !!!![[     0 336770      0      0]]\n",
      "70th row over !!!![[     0 341581      0      0]]\n",
      "71th row over !!!![[     0 346392      0      0]]\n",
      "72th row over !!!![[     0 351203      0      0]]\n",
      "73th row over !!!![[     0 356014      0      0]]\n",
      "74th row over !!!![[     0 360825      0      0]]\n",
      "75th row over !!!![[     0 365636      0      0]]\n",
      "76th row over !!!![[     0 370447      0      0]]\n",
      "77th row over !!!![[     0 375258      0      0]]\n",
      "78th row over !!!![[     0 380069      0      0]]\n",
      "79th row over !!!![[     0 384880      0      0]]\n",
      "80th row over !!!![[     0 389691      0      0]]\n",
      "81th row over !!!![[     0 394502      0      0]]\n",
      "82th row over !!!![[     0 399313      0      0]]\n",
      "83th row over !!!![[     0 404124      0      0]]\n",
      "84th row over !!!![[     0 408935      0      0]]\n",
      "85th row over !!!![[     0 413746      0      0]]\n",
      "86th row over !!!![[     0 418557      0      0]]\n",
      "87th row over !!!![[     0 423368      0      0]]\n",
      "88th row over !!!![[     0 428179      0      0]]\n",
      "89th row over !!!![[     0 432990      0      0]]\n",
      "90th row over !!!![[     0 437801      0      0]]\n",
      "91th row over !!!![[     0 442612      0      0]]\n",
      "92th row over !!!![[     0 447423      0      0]]\n",
      "93th row over !!!![[     0 452234      0      0]]\n",
      "94th row over !!!![[     0 457045      0      0]]\n",
      "95th row over !!!![[     0 461856      0      0]]\n",
      "96th row over !!!![[     0 466667      0      0]]\n",
      "97th row over !!!![[     0 471478      0      0]]\n",
      "98th row over !!!![[     0 476289      0      0]]\n",
      "99th row over !!!![[     0 481100      0      0]]\n",
      "100th row over !!!![[     0 485911      0      0]]\n",
      "101th row over !!!![[     0 490722      0      0]]\n",
      "102th row over !!!![[     0 495533      0      0]]\n",
      "103th row over !!!![[     0 500344      0      0]]\n",
      "104th row over !!!![[     0 505155      0      0]]\n",
      "105th row over !!!![[     0 509966      0      0]]\n",
      "106th row over !!!![[     0 514777      0      0]]\n",
      "107th row over !!!![[     0 519588      0      0]]\n",
      "108th row over !!!![[     0 524399      0      0]]\n",
      "109th row over !!!![[     0 529210      0      0]]\n",
      "110th row over !!!![[     0 534021      0      0]]\n",
      "111th row over !!!![[     0 538832      0      0]]\n",
      "112th row over !!!![[     0 543643      0      0]]\n",
      "113th row over !!!![[     0 548454      0      0]]\n",
      "114th row over !!!![[     0 553265      0      0]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-471-988c380d6071>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mtemp_arr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minp_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_arr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m             \u001b[0mcolour_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_arr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m             \u001b[0mcount_arr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolour_value\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[0mclassified_arr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolour_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36mpredict_classes\u001b[1;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[0;32m    265\u001b[0m             \u001b[0mA\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m         \"\"\"\n\u001b[1;32m--> 267\u001b[1;33m         \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    268\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mproba\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mproba\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1167\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1168\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1169\u001b[1;33m                                             steps=steps)\n\u001b[0m\u001b[0;32m   1170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1171\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[1;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m    292\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 294\u001b[1;33m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    295\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#print(arr[2].shape)\n",
    "#print(arr[3].shape)\n",
    "#colour_arr = np.zeros((3,arr[2].shape[0],arr[2].shape[1]),dtype='float64')\n",
    "#print(colour_arr.shape)\n",
    "count_arr = np.zeros((1,4),dtype = 'int64')\n",
    "#dict_colour = {0:(139,69,19),1:(128,128,128),2:(0,128,0),3:(0,0,255)}\n",
    "for i in range(arr[2].shape[0]) :\n",
    "    for j in range(arr[2].shape[1]) : \n",
    "        temp_arr[0] = inp_data[:,i,j]\n",
    "        if not math.isnan(temp_arr[0][0]) :\n",
    "            colour_value = model.predict_classes(temp_arr)\n",
    "            count_arr[0][colour_value] += 1\n",
    "            classified_arr[i][j] = colour_value\n",
    "        #rgb_val = dict_colour[classified_arr[i][j]]\n",
    "        #colour_arr[:,i,j] = rgb_val \n",
    "    print(str(i)+\"th row over !!!!\" + str(count_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(colour_arr.shape)\n",
    "#print(colour_arr)\n",
    "print(count_arr)\n",
    "#print(np.min(colour_arr[0]))\n",
    "#print(np.max(colour_arr[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "driver = gdal.GetDriverByName('GTiff')\n",
    "ds1 = driver.Create('final_marking1.tif',colour_arr.shape[2],colour_arr.shape[1],1, gdal.GDT_Float32)\n",
    "srs = osr.SpatialReference()\n",
    "srs.ImportFromEPSG(4326)  \n",
    "ds1.SetProjection(srs.ExportToWkt())\n",
    "ds1.SetGeoTransform(ds.GetGeoTransform())\n",
    "\n",
    "\n",
    "temp_ar=classified_arr\n",
    "outband=ds1.GetRasterBand(1)\n",
    "outband.SetStatistics(np.min(temp_ar), np.max(temp_ar), np.average(temp_ar),np.std(temp_ar))\n",
    "outband.WriteArray(temp_ar)\n",
    "outband.FlushCache()\n",
    "\n",
    "outband =None \n",
    "band = None\n",
    "ds1 = None\n",
    "ds=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
